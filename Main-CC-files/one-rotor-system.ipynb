{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import csv\n",
    "import functions as func\n",
    "import hamiltonianGenerator as hG\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the possible combinations of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = 3\n",
    "states = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.zeros((8,8))\n",
    "matrix[1,2] = 1\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.,  17.,  27.,  37.,  47.,  57.,  67.,  77.],\n",
       "       [107., 117., 127., 137., 147., 157., 167., 177.],\n",
       "       [207., 217., 227., 237., 247., 257., 267., 277.],\n",
       "       [307., 317., 327., 337., 347., 357., 367., 377.],\n",
       "       [407., 417., 427., 437., 447., 457., 467., 477.],\n",
       "       [507., 517., 527., 537., 547., 557., 567., 577.],\n",
       "       [607., 617., 627., 637., 647., 657., 667., 677.],\n",
       "       [707., 717., 727., 737., 747., 757., 767., 777.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in range(0,8):\n",
    "    for q in range(0,8):\n",
    "        for r in range(0,8):\n",
    "            matrix[r,q] = p + q*10 + r*100\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrix(site, state):\n",
    "    states = [\"\".join(map(str, digits)) for digits in product(range(state), repeat=site)]\n",
    "    matrix = []\n",
    "\n",
    "    for row in states:\n",
    "        row_entries = [f\"{row}|{col}\" for col in states]\n",
    "        matrix.append(row_entries)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def print_matrix(matrix):\n",
    "    for row in matrix:\n",
    "        print(\" \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000|000 000|001 000|010 000|011 000|100 000|101 000|110 000|111\n",
      "001|000 001|001 001|010 001|011 001|100 001|101 001|110 001|111\n",
      "010|000 010|001 010|010 010|011 010|100 010|101 010|110 010|111\n",
      "011|000 011|001 011|010 011|011 011|100 011|101 011|110 011|111\n",
      "100|000 100|001 100|010 100|011 100|100 100|101 100|110 100|111\n",
      "101|000 101|001 101|010 101|011 101|100 101|101 101|110 101|111\n",
      "110|000 110|001 110|010 110|011 110|100 110|101 110|110 110|111\n",
      "111|000 111|001 111|010 111|011 111|100 111|101 111|110 111|111\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "site = 3\n",
    "state = 2\n",
    "matrix = generate_matrix(site, state)\n",
    "print_matrix(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting from m to p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free one body system. (Work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 2  5  6  7]\n",
      " [ 3  6  8  9]\n",
      " [ 4  7  9 10]]\n",
      "(array([[0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [2]]), array([[0, 3, 1, 2]]))\n",
      "[[ 1  3  4  2]\n",
      " [ 3  8  9  6]\n",
      " [ 4  9 10  7]\n",
      " [ 2  6  7  5]]\n",
      "[[ 1.  3.  4.  2.]\n",
      " [ 3.  8.  9.  6.]\n",
      " [ 4.  9. 10.  7.]\n",
      " [ 2.  6.  7.  5.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Original matrix A\n",
    "A = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [2, 5, 6, 7],\n",
    "    [3, 6, 8, 9],\n",
    "    [4, 7, 9, 10]\n",
    "])\n",
    "print(A)\n",
    "# Index map: new_index[i] = index of row i in the new basis\n",
    "index_map = [0, 3, 1, 2]  # Example: remap row/col 1 → 3, 2 → 1, 3 → 2\n",
    "\n",
    "# Permute rows and columns accordingly\n",
    "A_new = A[np.ix_(index_map, index_map)]\n",
    "A_new = A_new.T[np.ix_(index_map, index_map)]\n",
    "\n",
    "print(np.ix_(index_map, index_map))\n",
    "\n",
    "print(A_new)\n",
    "\n",
    "P = np.eye(len(index_map))[index_map]\n",
    "A_new2 = P.T @ A @ P\n",
    "\n",
    "print(A_new2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  1.  4.  4.  9.  9. 16. 16. 25. 25.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 16.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 16.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 25.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 25.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def free_one_body(max_m: int)-> np.array:\n",
    "\n",
    "    p_max = 2*max_m + 1\n",
    "    p_vect = np.zeros(p_max)\n",
    "\n",
    "    m = 0\n",
    "\n",
    "    for i in range(1, max_m+1):\n",
    "\n",
    "        p_vect[i + m] = i**2\n",
    "        p_vect[i + 1 + m] = (-i)**2\n",
    "        m+=1\n",
    "    \n",
    "    print(p_vect)\n",
    "\n",
    "    return  np.diag(p_vect)\n",
    "\n",
    "K_new = free_one_body(5)\n",
    "\n",
    "K_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1    2    3    4    5    6    7    8     9     10\n",
      "0   25.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "1    0.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "2    0.0   0.0  9.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "3    0.0   0.0  0.0  4.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "4    0.0   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "5    0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "6    0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0   0.0\n",
      "7    0.0   0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0   0.0   0.0\n",
      "8    0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  9.0   0.0   0.0\n",
      "9    0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  16.0   0.0\n",
      "10   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  25.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/gilfrim/Desktop/QuantumChemistryCoop/Main-CC-files/matrix_elements_K.csv\",\n",
    "    skiprows=1, header=0\n",
    ")\n",
    "\n",
    "# Clean column names\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "# Convert columns safely\n",
    "df[\"m1\"] = df[\"m1\"].astype(int)\n",
    "df[\"m2\"] = df[\"m2\"].astype(int)\n",
    "df[\"<m1|K|m2>\"] = df[\"<m1|K|m2>\"].astype(float)\n",
    "\n",
    "# Matrix size and init\n",
    "size = max(df[\"m1\"].max(), df[\"m2\"].max()) + 1\n",
    "K = np.zeros((size, size))\n",
    "\n",
    "m = (size - 1) / 2\n",
    "\n",
    "# Fill matrix\n",
    "for _, row in df.iterrows():\n",
    "\n",
    "    i = int(row[\"m1\"])\n",
    "    j = int(row[\"m2\"])\n",
    "    val = float(row[\"<m1|K|m2>\"])\n",
    "    K[i, j] = val\n",
    "    K[j, i] = val\n",
    "\n",
    "    \n",
    "# Show matrix\n",
    "print(pd.DataFrame(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1  1 -2  2 -3  3 -4  4 -5  5]\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "# p_vect = np.zeros(11)\n",
    "p_vect = np.array([0,  -1, 1,  -2, 2,  -3, 3,  -4, 4,  -5, 5])\n",
    "m=0\n",
    "vec1 = np.zeros(11)\n",
    "\n",
    "for i in range(11):\n",
    "    vec1[i] = int(func.m_to_p(p_vect[i]))\n",
    "\n",
    "print(p_vect)\n",
    "print(vec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free one body system. (Final Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 15 13 11  9  7  5  3  1  0  2  4  6  8 10 12 14 16 18]\n",
      "     0    1     2    3    4     5    6     7    8    9     10\n",
      "0   9.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "1   0.0  1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "2   0.0  0.0  25.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "3   0.0  0.0   0.0  4.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "4   0.0  0.0   0.0  0.0  4.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "5   0.0  0.0   0.0  0.0  0.0  16.0  0.0   0.0  0.0  0.0   0.0\n",
      "6   0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "7   0.0  0.0   0.0  0.0  0.0   0.0  0.0  16.0  0.0  0.0   0.0\n",
      "8   0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  9.0  0.0   0.0\n",
      "9   0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  1.0   0.0\n",
      "10  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  25.0\n"
     ]
    }
   ],
   "source": [
    "def create_index_map(total_num_states: int)->np.array:\n",
    "\n",
    "    index_map = np.arange(-total_num_states,total_num_states+1)\n",
    "\n",
    "    vectorised_m_to_p = np.vectorize(func.m_to_p)\n",
    "    index_map = vectorised_m_to_p(index_map)\n",
    "\n",
    "    return index_map\n",
    "\n",
    "print(create_index_map(9))\n",
    "\n",
    "def basis_m_to_p_matrix_conversion(matrix: np.ndarray)->np.ndarray:\n",
    "\n",
    "    dim = matrix.shape[0]\n",
    "    index_map = create_index_map((dim-1)//2)\n",
    "\n",
    "    matrix = matrix[np.ix_(index_map, index_map)]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "print(pd.DataFrame(basis_m_to_p_matrix_conversion(K)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1    2    3    4    5    6    7    8     9     10\n",
      "0   25.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "1    0.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "2    0.0   0.0  9.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "3    0.0   0.0  0.0  4.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "4    0.0   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "5    0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "6    0.0   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0   0.0\n",
      "7    0.0   0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0   0.0   0.0\n",
      "8    0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  9.0   0.0   0.0\n",
      "9    0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  16.0   0.0\n",
      "10   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  25.0\n",
      "     0    1     2    3    4     5    6     7    8    9     10\n",
      "0   9.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "1   0.0  1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "2   0.0  0.0  25.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "3   0.0  0.0   0.0  4.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "4   0.0  0.0   0.0  0.0  4.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "5   0.0  0.0   0.0  0.0  0.0  16.0  0.0   0.0  0.0  0.0   0.0\n",
      "6   0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0   0.0\n",
      "7   0.0  0.0   0.0  0.0  0.0   0.0  0.0  16.0  0.0  0.0   0.0\n",
      "8   0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  9.0  0.0   0.0\n",
      "9   0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  1.0   0.0\n",
      "10  0.0  0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  25.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/gilfrim/Desktop/QuantumChemistryCoop/Main-CC-files/matrix_elements_K.csv\",\n",
    "    skiprows=1, header=0\n",
    ")\n",
    "\n",
    "# Clean column names\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "# Convert columns safely\n",
    "df[\"m1\"] = df[\"m1\"].astype(int)\n",
    "df[\"m2\"] = df[\"m2\"].astype(int)\n",
    "df[\"<m1|K|m2>\"] = df[\"<m1|K|m2>\"].astype(float)\n",
    "\n",
    "# Matrix size and init\n",
    "size = max(df[\"m1\"].max(), df[\"m2\"].max()) + 1\n",
    "K = np.zeros((size, size))\n",
    "\n",
    "m = (size - 1) / 2\n",
    "\n",
    "# Fill matrix\n",
    "for _, row in df.iterrows():\n",
    "\n",
    "    i = int(row[\"m1\"])\n",
    "    j = int(row[\"m2\"])\n",
    "    val = float(row[\"<m1|K|m2>\"])\n",
    "    K[i, j] = val\n",
    "    K[j, i] = val\n",
    "\n",
    "    \n",
    "# Show matrix\n",
    "print(pd.DataFrame(K))\n",
    "\n",
    "print(pd.DataFrame(basis_m_to_p_matrix_conversion(K)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coplaner two body system. (Work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning einsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inner product of vectors\n",
    "\n",
    "'i,i->': sum over index i (vector inner product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "np.dot(a, b)         # → 32\n",
    "np.einsum('i,i->', a, b)  # → 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Matrix multiplication\n",
    "\n",
    "'ik,kj->ij': sum over index k (standard matrix multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4],\n",
       "       [10,  8]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[2, 0], [1, 2]])\n",
    "\n",
    "np.matmul(A, B)\n",
    "np.einsum('ik,kj->ij', A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Trace of a matrix\n",
    "\n",
    "'ii->': sum diagonal elements (same index repeated = sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5],\n",
       "       [ 6,  8, 10]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4, 5])\n",
    "\n",
    "np.einsum('i,j->ij', a, b)\n",
    "# Result: 2x3 matrix of a[i] * b[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Tensor contraction\n",
    "\n",
    "Contracts the last index of T with w (like applying weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93882073, 0.96995704, 1.08514116],\n",
       "       [0.734377  , 0.76955526, 0.76790332]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.random.rand(2, 3, 4)\n",
    "w = np.random.rand(4)\n",
    "\n",
    "np.einsum('ijk,k->ij', T, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Outer product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5],\n",
       "       [ 6,  8, 10]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4, 5])\n",
    "\n",
    "np.einsum('i,j->ij', a, b)\n",
    "# Result: 2x3 matrix of a[i] * b[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor (flattened):\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[[1, 0, 2], [1, 0, 2]]\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "Original slice T[0, 1, :, :]:\n",
      "[[110 120 130]\n",
      " [210 220 230]\n",
      " [310 320 330]]\n",
      "\n",
      "Permuted slice T_permuted[0, 1, :, :]:\n",
      "[[220 210 230]\n",
      " [120 110 130]\n",
      " [320 310 330]]\n",
      "[[220. 210. 230.]\n",
      " [120. 110. 130.]\n",
      " [320. 310. 330.]]\n",
      "[[220. 210. 230.]\n",
      " [120. 110. 130.]\n",
      " [320. 310. 330.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T = np.arange(3**2).reshape(3, 3)\n",
    "print(\"Original Tensor (flattened):\")\n",
    "print(T.flatten())\n",
    "\n",
    "for i in range(1, 4):\n",
    "    for j in range(1, 4):\n",
    "        T[i-1,j-1] = 100*i+10*j\n",
    "\n",
    "index_map = [1, 0, 2]  # Permute axis 0\n",
    "index_maps = []\n",
    "for i in range(2):\n",
    "    index_maps.append(index_map)\n",
    "\n",
    "print(index_maps)\n",
    "# Unpack index_maps into np.ix_\n",
    "T_permuted = T[np.ix_(*index_maps)]\n",
    "\n",
    "P = np.eye(len(index_map))[index_map]\n",
    "T_einsum = np.einsum('ai,bj,ij->ab', P, P, T)\n",
    "\n",
    "print(P.shape)\n",
    "print(T.shape)\n",
    "\n",
    "T_change_of_bais = P.T @ T @ P\n",
    "\n",
    "print(\"Original slice T[0, 1, :, :]:\")\n",
    "print(T)\n",
    "\n",
    "print(\"\\nPermuted slice T_permuted[0, 1, :, :]:\")\n",
    "print(T_permuted)\n",
    "print(T_einsum)\n",
    "print(T_change_of_bais)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor (flattened):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26]\n",
      "[[1, 0, 2], [1, 0, 2], [1, 0, 2]]\n",
      "Original slice T[0, 1, :, :]:\n",
      "[[111 112 113]\n",
      " [121 122 123]\n",
      " [131 132 133]]\n",
      "\n",
      "Permuted slice T_permuted[0, 1, :, :]:\n",
      "[[222 221 223]\n",
      " [212 211 213]\n",
      " [232 231 233]]\n",
      "[[1, 0, 2], [1, 0, 2], [1, 0, 2]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T = np.arange(3**3).reshape(3, 3, 3)\n",
    "print(\"Original Tensor (flattened):\")\n",
    "print(T.flatten())\n",
    "\n",
    "for i in range(1, 4):\n",
    "    for j in range(1, 4):\n",
    "        for k in range(1, 4):\n",
    "            T[i-1,j-1,k-1] = 100*i+10*j+k\n",
    "\n",
    "index_map = [1, 0, 2]  # Permute axis 0\n",
    "index_maps = []\n",
    "for i in range(3):\n",
    "    index_maps.append(index_map)\n",
    "\n",
    "print(index_maps)\n",
    "# Unpack index_maps into np.ix_\n",
    "T_permuted = T[np.ix_(*index_maps)]\n",
    "\n",
    "print(\"Original slice T[0, 1, :, :]:\")\n",
    "print(T[0, :, :])\n",
    "\n",
    "print(\"\\nPermuted slice T_permuted[0, 1, :, :]:\")\n",
    "print(T_permuted[0, :, :])\n",
    "\n",
    "print(index_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[111, 112, 113],\n",
       "        [121, 122, 123],\n",
       "        [131, 132, 133]],\n",
       "\n",
       "       [[211, 212, 213],\n",
       "        [221, 222, 223],\n",
       "        [231, 232, 233]],\n",
       "\n",
       "       [[311, 312, 313],\n",
       "        [321, 322, 323],\n",
       "        [331, 332, 333]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coplaner two body system. (Final Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n",
      "[array([1, 0, 2]), array([1, 0, 2]), array([1, 0, 2])]\n",
      "[[[222 221 223]\n",
      "  [212 211 213]\n",
      "  [232 231 233]]\n",
      "\n",
      " [[122 121 123]\n",
      "  [112 111 113]\n",
      "  [132 131 133]]\n",
      "\n",
      " [[322 321 323]\n",
      "  [312 311 313]\n",
      "  [332 331 333]]]\n"
     ]
    }
   ],
   "source": [
    "def create_index_map(total_num_states: int)->np.array:\n",
    "\n",
    "    index_map = np.arange(-total_num_states,total_num_states+1)\n",
    "\n",
    "    vectorised_m_to_p = np.vectorize(func.m_to_p)\n",
    "    index_map = vectorised_m_to_p(index_map)\n",
    "\n",
    "    return index_map\n",
    "\n",
    "print(create_index_map(1))\n",
    "\n",
    "def basis_m_to_p_matrix_conversion(matrix: np.ndarray)->np.ndarray:\n",
    "\n",
    "    dim = matrix.shape[0]\n",
    "    index_map = create_index_map((dim-1)//2)\n",
    "\n",
    "    index_maps = []\n",
    "    for i in range(dim):\n",
    "        index_maps.append(index_map)\n",
    "\n",
    "    print(index_maps)\n",
    "\n",
    "    matrix = matrix[np.ix_(*index_maps)]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "print(basis_m_to_p_matrix_conversion(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sheres matrix with numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "V = 0.75 \\sum_{m_1, m_2} \\left( |m_1, m_2\\rangle \\langle m_1 + 1, m_2 + 1| + |m_1, m_2\\rangle \\langle m_1 - 1, m_2 - 1| \\right) \\\\\n",
    "\\quad -\\ 0.25 \\sum_{m_1, m_2} \\left( |m_1, m_2\\rangle \\langle m_1 - 1, m_2 + 1| + |m_1, m_2\\rangle \\langle m_1 + 1, m_2 - 1| \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9    ...  111  112  113  \\\n",
      "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "116  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "117  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "118  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "119  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "120  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "     114  115  116  117  118  119  120  \n",
      "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  \n",
      "116  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "117  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "118  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "119  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "120  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[121 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import hamiltonianGenerator as hg\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(suppress = True, linewidth = 10000, threshold = 1000000, precision = 6)\n",
    "\n",
    "# Script for diagonalizing the Hamiltonian for 2 dipolar rotors oriented along the x direction. \n",
    "# m_max = 5 is sufficient for convergence when studying ground state properties. \n",
    "m_max = 5\n",
    "d = 2*m_max + 1\n",
    "K_1 = np.zeros((d,d))\n",
    "for i in range(d):\n",
    "    K_1[i,i] = hg.free_one_body(i, i, m_max)\n",
    "\n",
    "K_2 = np.kron(K_1, np.eye(d)) + np.kron(np.eye(d), K_1)\n",
    "\n",
    "# Interaction for a coplanar chain is proportional to (yiyj + 2xixj)/r^3. If sites are not coplanar, \n",
    "# the interaction will be some other linear combination of xixj, yiyj, (xiyj + xjyi). The coefficients \n",
    "# will, in general, depend on the angle as well as the length of the vector connecting the sites. \n",
    "V2 = np.zeros((d**2, d**2))\n",
    "\n",
    "for i in range(d):\n",
    "    for j in range(d):\n",
    "        for k in range(d):\n",
    "            for l in range(d):\n",
    "                V2[i*d + j,k*d + l] = hg.interaction_yiyj(i, j, k, l) + 2*hg.interaction_xixj(i, j, k, l)\n",
    "'''\n",
    "num_pts = 20\n",
    "E0_array = np.zeros((num_pts, 2))\n",
    "for i in range(num_pts):\n",
    "    g = (i+1.0)/num_pts\n",
    "    H_2 = K_2 + g * V_2\n",
    "    evals, evecs = np.linalg.eigh(H_2)\n",
    "    E0 = evals[0]\n",
    "    E0_array[i, 0] = g\n",
    "    E0_array[i, 1] = E0\n",
    "\n",
    "np.savetxt(\"E0_N2_ED.csv\", E0_array, delimiter=\",\", header=\"g, E0\")'''\n",
    "\n",
    "\n",
    "print(pd.DataFrame(V2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
